# 核心工具是scipy.optimize.curve_fit。工作原理是：
# 你给它一个目标函数的形式，例如 y = f(x, param1, param2, ...)。
# 你给它一组实际的观测数据 (x_data, y_data)。
# 它会通过迭代计算，调整param1, param2等参数的值，
# 来使得你的目标函数计算出的y值与实际的y_data之间的残差平方和（Sum of Squared Residuals）最小。
# 当残差平方和最小时，它就找到了最能“拟合”你数据的参数值。


# 准备数据:
# 从CSV和Excel中，提取出所有“挖墙脚”的决策记录。
# 计算出每次决策的 score_diff = Sa - Sb 和结果 result (0或1)。
# 数据分箱 (Binning)：这是一个关键步骤。我们不直接拟合0/1的散点，因为那样噪音太大。
# 我们将score_diff的值域分成20个小区间（“箱子”）。
# 对每个箱子，我们计算其中所有决策的平均接受率（result的均值）。
# 例如，在分数差为10到12之间的所有决策中，有60%被接受了。
# 我们还计算每个箱子的中间值 diff_mid。
# 这样我们就得到了一组更平滑的数据点 (x_data = diff_mid, y_data = average_acceptance_rate)。
# 筛选拟合数据:
# 我们只选择 x_data > 0 的数据点（即 Sa > Sb 的情况）来进行拟合，因为指数模型不适合描述 Sa < Sb 的情况。
# fit_data_taken = binned_taken[binned_taken['diff_mid'] > 0]






# 1. 对“优势差异”的敏感度 (λ): 英文模式非常理性，中文模式近乎随机
# 英文组 (λ ≈ 0.2185):
# λ 是一个显著的正数，意味着接受概率随着新追求者比现任伴侣的优势（Sa - Sb）增大而急剧上升。
# 左图的红色指数曲线非常陡峭，完美地捕捉了这种趋势：当新追求者的分数仅比现任高出10-20分时，
# 接受（换人）的概率就从接近0飙升到50%以上。
# 结论: 在英文语境下，GPT-4表现得像一个高度理性的“收益最大化者”。
# 它对候选人之间的分数差异极其敏感，一旦出现更优选择，它会毫不犹豫地做出更换决策。

# 中文组 (λ ≈ 0.0035):
# λ 非常非常小，接近于0。这意味着接受概率几乎不随新追求者的优势（Sa - Sb）变化而变化。
# 左图的红色“指数”曲线几乎是一条平缓的直线，完全没有体现出指数增长的趋势。它只是勉强穿过了Sa > Sb区域的数据点。
# 结论: 在中文语境下，GPT-t4在面对“挖墙脚”情景时，其决策几乎是随机的，
# 或者说对分数差异完全不敏感。它的接受概率似乎稳定在50%-60%左右，
# 无论新追求者是稍微好一点，还是好很多。这可能暗示着一种“犹豫不决”、“不想得罪人”或者完全不同的、非量化的决策逻辑。





# 2. 对单身求偶的接受门槛 (S_threshold): 英文模式有明确标准，中文模式“来者不拒”
# 英文组 (S_threshold ≈ 36.20):
# 这个阈值是一个合理的正数。它意味着，当一个单身的追求者总分低于36.20时，GPT-4（英文）倾向于拒绝；
# 当分数高于这个值时，接受的概率迅速增加。
# 右图的绿色Sigmoid曲线清晰地展示了这个S型过渡区，红色虚线准确地标出了这个决策“拐点”。
# 结论: 在英文语境下，GPT-4对于新伴侣有一个明确的、可量化的“最低接受标准”。它会评估追求者是否“及格”。
# 中文组 (S_threshold ≈ -32.75):
# 这个阈值是一个毫无意义的负数。总分不可能是负的。
# 为什么会出现这种情况？ 看右图的数据点，当追求者分数 S 很低时，
# 接受率就已经非常高了（基本都在80%以上，甚至100%）。为了拟合这些数据点，
# 模型只能将“50%接受率”的那个拐点推到远小于0的区域。
# 结论: 在中文语境下，GPT-4对于单身求偶者几乎没有设立任何分数门槛，
# 表现出“来者不拒”的态度。只要有人来求偶，无论其分数如何，接受的概率都非常高。
# 这与“挖墙脚”场景下的“随机”行为形成了有趣的对比。